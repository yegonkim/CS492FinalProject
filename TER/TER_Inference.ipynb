{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PC_vD2l0VcWJ"
      },
      "source": [
        "> This `ipynb` file shows you an example of how to make inferences. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGTrN2EnZvHJ"
      },
      "outputs": [],
      "source": [
        "!gdown https://drive.google.com/uc?id=14EE8yxx4q9TKL6dDNfsVWlGW-S0-tNnx\n",
        "!mv bert-best.pth /content/CS492FinalProject/TER\n",
        "!git clone https://github.com/yegonkim/CS492FinalProject.git  \n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnz6kTT1ZzqA",
        "outputId": "64799847-1fa1-4fb7-b526-17dd7d4169c8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'emotion': 'anger', 'text': 'This is not a black pencil.'}"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "sys.path.insert(1, '/content/CS492FinalProject/TER/')\n",
        "\n",
        "from CS492FinalProject.TER import inference\n",
        "\n",
        "results = []\n",
        "sentences = ['I finally achieved the dream of my life!', 'I’m really excited for the final exams.', \n",
        "             'I want to sleep right now.', 'I closed the window because it was cold.', \n",
        "             'I am so scared because I lost my homework and I am going to get a bad grade.','I’m worried that I wouldn’t be able to say anything in front of them.',\n",
        "             'How dare he steal my freaking wallet?', 'I really wanted to hit him in the face.',\n",
        "             'Unfortunately, I could not finish my homework in time.', 'My grandma passed away two years ago.'\n",
        "             ]\n",
        "\n",
        "for sent in sentences:\n",
        "  results.append(inference.infer(sent))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for result in results:\n",
        "  print(result)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "TER_Inference.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
